package summarize

import (
	"bytes"
	"errors"
	"fmt"
	"io"
	"math"
	"net/url"
	"time"

	"github.com/go-shiori/go-readability"
	"github.com/imroc/req/v3"
	tokenizer "github.com/pandodao/tokenizer-go"
	"github.com/samber/lo"
	goopenai "github.com/sashabaranov/go-openai"
	"github.com/sirupsen/logrus"
)

var (
	ErrNetworkError        = errors.New("network error")
	ErrRequestFailed       = errors.New("request failed")
	ErrContentNotSupported = errors.New("content not supported")
)

func (h *Handler) summarizeInputURL(url string) (string, error) {
	article, err := extractContentFromURL(url)
	if err != nil {
		return "", fmt.Errorf("failed to parse %s, %w", url, err)
	}

	textContent, err := truncateContentBasedOnTokens(article.TextContent)
	if err != nil {
		return "", fmt.Errorf("failed to truncate content based on tokens... %w", err)
	}

	h.Logger.WithFields(logrus.Fields{
		"title": article.Title,
		"url":   url,
	}).Infof("‚úçÔ∏è summarizing article...")
	resp, err := h.OpenAI.SummarizeWithQuestionsAsSimplifiedChinese(
		article.Title,
		article.Byline,
		textContent,
	)
	if err != nil {
		return "", fmt.Errorf("failed to create chat completion for summarizing... %w", err)
	}

	respMessages := lo.Map(resp.Choices, func(item goopenai.ChatCompletionChoice, _ int) string {
		return item.Message.Content
	})
	if len(respMessages) == 0 {
		return "", fmt.Errorf("no response from OpenAI")
	}

	h.Logger.WithFields(logrus.Fields{
		"title":                  article.Title,
		"url":                    url,
		"prompt_token_usage":     resp.Usage.PromptTokens,
		"completion_token_usage": resp.Usage.CompletionTokens,
		"total_token_usage":      resp.Usage.TotalTokens,
	}).Infof("‚úÖ summarizing article done")
	return fmt.Sprintf("<b><a href=\"%s\">%s</a></b>\n%s\n\n<em>ü§ñÔ∏è Generated by chatGPT</em>", url, article.Title, respMessages[0]), nil
}

func extractContentFromURL(urlString string) (*readability.Article, error) {
	parsedURL, err := url.Parse(urlString)
	if err != nil {
		return nil, err
	}
	if parsedURL == nil {
		return nil, errors.New("empty url")
	}

	resp, err := req.
		C().
		SetUserAgent("Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36 Edg/111.0.1661.54").
		SetTimeout(time.Minute).
		R().
		Get(parsedURL.String())
	if err != nil {
		return nil, fmt.Errorf("failed to get url %s, %w: %v", parsedURL.String(), ErrNetworkError, err)
	}
	if !resp.IsSuccess() {
		return nil, fmt.Errorf("failed to get url %s, %w, status code: %d, dump: %s", parsedURL.String(), ErrRequestFailed, resp.StatusCode, resp.Dump())
	}
	if !lo.Contains([]string{
		"text/html",
	}, resp.Header.Get("Content-Type")) {
		return nil, fmt.Errorf("url fetched, but content-type not supported yet, %w, content-type: %s", ErrContentNotSupported, resp.Header.Get("Content-Type"))
	}

	buffer := new(bytes.Buffer)
	_, err = io.Copy(buffer, resp.Body)
	if err != nil {
		return nil, err
	}

	urlContent, err := readability.FromReader(buffer, parsedURL)
	if err != nil {
		return nil, err
	}

	return &urlContent, nil
}

// truncateContentBasedOnTokens Âü∫‰∫é token ËÆ°ÁÆóÁöÑÊñπÂºèÊà™Êñ≠ÊñáÊú¨
func truncateContentBasedOnTokens(textContent string) (string, error) {
	tokens, err := tokenizer.CalToken(textContent)
	if err != nil {
		return "", err
	}
	if tokens > 3900 {
		return string([]rune(textContent)[:int(math.Min(3900, float64(len([]rune(textContent)))))]), nil
	}

	return textContent, nil
}
