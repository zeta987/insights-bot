package telegraph

import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/celestix/telegraph-go/v2"
	"github.com/nekomeowww/insights-bot/internal/thirdparty/openai"
	"github.com/sourcegraph/conc"
	"go.uber.org/fx"
	"go.uber.org/zap"

	tgbotapi "github.com/go-telegram-bot-api/telegram-bot-api/v5"
	"github.com/nekomeowww/insights-bot/internal/configs"
	"github.com/nekomeowww/insights-bot/pkg/logger"
)

var Module = fx.Options(
	fx.Provide(NewService),
)

const (
	maxRetries         = 3
	retryDelay         = 1 * time.Second
	pageCreateInterval = 2 * time.Second // throttle between createPage calls
	pageSizeLimit      = 60 * 1024       // 60 KB limit for content
	safetyBuffer       = 2 * 1024        // 2 KB safety buffer for serialization overhead
)

type Service struct {
	cfg    *configs.Config
	client *telegraph.TelegraphClient
	openai openai.Client
	logger *logger.Logger
	bot    *tgbotapi.BotAPI
}

type NewServiceParams struct {
	fx.In

	Config    *configs.Config
	Client    *telegraph.TelegraphClient
	OpenAI    openai.Client
	Logger    *logger.Logger
	Lifecycle fx.Lifecycle
}

func NewService(params NewServiceParams) *Service {
	service := &Service{
		cfg:    params.Config,
		client: params.Client,
		openai: params.OpenAI,
		logger: params.Logger,
	}

	var err error
	service.bot, err = tgbotapi.NewBotAPI(params.Config.Telegram.BotToken)
	if err != nil {
		service.logger.Error("failed to create telegram bot API", zap.Error(err))
	}

	params.Lifecycle.Append(fx.Hook{
		OnStart: func(context.Context) error {
			go service.maybeRunPagingTest() // å•Ÿå‹•æ¸¬è©¦
			return nil
		},
	})

	return service
}

func init() {
	// no-op placeholder to satisfy linter for possible future init logic
}

func (s *Service) maybeRunPagingTest() {
	if !s.cfg.TelegraphPagingTestEnabled {
		return
	}

	s.logger.Info("paging test: enabled, starting test")

	// 1. æª¢æŸ¥æ¸¬è©¦æ–‡ä»¶è·¯å¾‘
	if s.cfg.TelegraphPagingTestFile == "" {
		s.logger.Error("paging test: TELEGRAPH_PAGING_TEST_FILE not configured")
		return
	}

	// ä½¿ç”¨çµ•å°è·¯å¾‘
	testFilePath := s.cfg.TelegraphPagingTestFile
	if !strings.HasPrefix(testFilePath, "/") && !strings.Contains(testFilePath, ":\\") {
		// å¦‚æœæ˜¯ç›¸å°è·¯å¾‘ï¼Œè½‰æ›ç‚ºçµ•å°è·¯å¾‘
		pwd, err := os.Getwd()
		if err != nil {
			s.logger.Error("paging test: failed to get working directory",
				zap.Error(err))
			return
		}
		testFilePath = filepath.Join(pwd, testFilePath)
	}

	s.logger.Info("paging test: using test file",
		zap.String("file_path", testFilePath))

	// 2. è®€å–æ¸¬è©¦æ–‡ä»¶å…§å®¹
	testContent, err := os.ReadFile(testFilePath)
	if err != nil {
		s.logger.Error("paging test: failed to read test file",
			zap.Error(err),
			zap.String("file_path", testFilePath))
		return
	}

	if len(testContent) == 0 {
		s.logger.Error("paging test: test file is empty",
			zap.String("file_path", testFilePath))
		return
	}

	testContentStr := string(testContent)

	// 3. å»ºç«‹æ™‚é–“æˆ³è¨˜å’Œæ¨™é¡Œ
	timestamp := time.Now().Format("2006-01-02 15:04:05")
	// ä½¿ç”¨æ›´æœ‰æ„ç¾©çš„æ¨™é¡Œæ ¼å¼ï¼Œæ¨¡æ“¬ç¾¤çµ„åã€ç”¨æˆ¶å’Œæ™‚é–“
	groupName := "ZETAçš„AIè³‡æ–™ç¾¤çµ„"
	userName := "æ¸¬è©¦ç”¨æˆ¶"
	baseTitle := fmt.Sprintf("%s %sè§¸ç™¼ %s", groupName, userName, timestamp)

	// 4. å…ˆä½¿ç”¨ OpenAI ç”Ÿæˆæ‘˜è¦ï¼ˆRecapï¼‰
	var recapMarkdown string
	var sarcasticSummary string

	if s.openai != nil {
		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)
		defer cancel()

		// å°‡å…§å®¹æ ¹æ“š token é™åˆ¶æˆªæ–·ï¼Œé¿å… prompt éé•·
		truncated := testContentStr
		if len(testContentStr) > 30000 {
			truncated = testContentStr[:30000]
			s.logger.Info("paging test: content truncated from original length",
				zap.Int("original_length", len(testContentStr)),
				zap.Int("truncated_length", 30000))
		}

		// å…ˆç”Ÿæˆè©³ç´°æ‘˜è¦
		s.logger.Info("paging test: requesting OpenAI for detailed summary")
		summaryResp, err := s.openai.SummarizeAny(ctx, truncated)
		if err != nil {
			s.logger.Warn("paging test: failed to get detailed summary", zap.Error(err))
		} else if len(summaryResp.Choices) > 0 {
			recapMarkdown = strings.TrimSpace(summaryResp.Choices[0].Message.Content)
			s.logger.Info("paging test: successfully generated detailed summary",
				zap.Int("length", len(recapMarkdown)))
		}

		// å†ç”ŸæˆéŠ³è©•å¼æ¿ƒç¸®ç¸½çµ
		if recapMarkdown != "" {
			s.logger.Info("paging test: requesting OpenAI for sarcastic condensed summary")
			sarcasticSummary, err = s.openai.SarcasticCondense(ctx, recapMarkdown)
			if err != nil {
				s.logger.Warn("paging test: failed to get sarcastic summary", zap.Error(err))
			} else {
				sarcasticSummary = strings.TrimSpace(sarcasticSummary)
				s.logger.Info("paging test: successfully generated sarcastic summary",
					zap.Int("length", len(sarcasticSummary)))
			}
		}
	}

	// å¦‚æœæ²’æœ‰ç²å–åˆ° OpenAI çš„æ‘˜è¦ï¼Œä½¿ç”¨é è¨­æ–‡æœ¬
	if recapMarkdown == "" {
		excerpt := testContentStr
		if len(excerpt) > 500 {
			excerpt = excerpt[:500]
		}
		recapMarkdown = fmt.Sprintf("(Recap ç”Ÿæˆå¤±æ•—ï¼Œä»¥ä¸‹ç‚ºåŸå§‹å…§å®¹ç¯€éŒ„)\n\n%s", excerpt)
	}

	if sarcasticSummary == "" {
		sarcasticSummary = "Telegraph é•·æ–‡æœ¬åˆ†é æ¸¬è©¦å…§å®¹ã€‚"
	}

	// 5. å°‡ Markdown è½‰æ›ç‚º HTML
	htmlContent := fmt.Sprintf("<h3>ğŸ“ èŠå¤©æ‘˜è¦</h3><p>%s</p><hr><h3>ğŸ’¬ åŸå§‹å…§å®¹</h3><p>%s</p>",
		strings.ReplaceAll(recapMarkdown, "\n\n", "</p><p>"),
		strings.ReplaceAll(testContentStr, "\n", "</p><p>"))

	// 6. å‰µå»º Telegraph é é¢ï¼ˆæ”¯æ´è‡ªå‹•åˆ†é ï¼‰
	var urls []string

	// æª¢æ¸¬æ˜¯å¦éœ€è¦åˆ†é ï¼ˆæ ¹æ“šåºåˆ—åŒ–å¾Œçš„å¯¦éš› JSON å¤§å°ï¼‰
	needPaging := func(html string) bool {
		nodes, err := telegraph.ContentFormat(html)
		if err != nil {
			s.logger.Warn("failed to format content for paging check", zap.Error(err))
			return len(html) > pageSizeLimit-safetyBuffer
		}
		jsonBytes, err := json.Marshal(nodes)
		if err != nil {
			s.logger.Warn("failed to marshal nodes for paging check", zap.Error(err))
			return len(html) > pageSizeLimit-safetyBuffer
		}
		s.logger.Info("paging test: content size check",
			zap.Int("json_size", len(jsonBytes)),
			zap.Int("limit", pageSizeLimit),
			zap.Bool("needs_paging", len(jsonBytes) > pageSizeLimit-safetyBuffer))
		return len(jsonBytes) > pageSizeLimit-safetyBuffer
	}

	if needPaging(htmlContent) {
		// ä½¿ç”¨å¤šé æ–¹æ³•
		s.logger.Info("paging test: content needs paging, creating page series")
		urls, err = s.CreatePageSeries(context.Background(), baseTitle, htmlContent)
		if err != nil {
			s.logger.Error("paging test: failed to create telegraph page series",
				zap.Error(err),
				zap.String("title", baseTitle))
			return
		}

		if len(urls) == 0 {
			s.logger.Error("paging test: no telegraph URLs returned")
			return
		}
	} else {
		// ä½¿ç”¨å–®é æ–¹æ³•
		s.logger.Info("paging test: content fits in single page")
		singlePageURL, err := s.CreatePage(context.Background(), baseTitle, htmlContent)
		if err != nil {
			s.logger.Error("paging test: failed to create telegraph page",
				zap.Error(err),
				zap.String("title", baseTitle))
			return
		}
		urls = []string{singlePageURL}
	}

	// 7. ç™¼é€è¨Šæ¯åˆ°æ¸¬è©¦ç¾¤çµ„
	if s.cfg.AutoRecapTestChatID == 0 {
		s.logger.Error("paging test: AUTO_RECAP_TEST_CHAT_ID not configured")
		return
	}

	// ç”Ÿæˆè¨Šæ¯æ ¼å¼
	var pagesInfo string
	if len(urls) > 1 {
		// å¤šé ï¼šåˆ—å‡ºå„é é€£çµ
		pagesLinks := make([]string, len(urls))
		for i, url := range urls {
			pagesLinks[i] = fmt.Sprintf("<a href=\"%s\">ç¬¬ %d éƒ¨åˆ†</a>", url, i+1)
		}
		pagesInfo = fmt.Sprintf("ğŸ“‘ <b>åˆ†é ç¸½çµ</b>ï¼š%s", strings.Join(pagesLinks, " | "))
	} else if len(urls) == 1 {
		// å–®é ï¼šåªé¡¯ç¤ºä¸€å€‹é€£çµ
		pagesInfo = fmt.Sprintf("ğŸ“ <a href=\"%s\">æŸ¥çœ‹å®Œæ•´ç¸½çµ</a>", urls[0])
	}

	// çµ„åˆè¨Šæ¯å…§å®¹
	messageText := fmt.Sprintf("ğŸ”„ <b>%s èŠå¤©ç¸½çµ</b>\n\n<b>æ™‚é–“:</b> %s\n<b>è§¸ç™¼:</b> %s\n\n%s\n\n<b>ğŸ’¡ éŠ³è©•:</b>\n%s",
		groupName,
		timestamp,
		userName,
		pagesInfo,
		sarcasticSummary)

	// ç™¼é€åˆ°æ¸¬è©¦ç¾¤çµ„
	msg := tgbotapi.NewMessage(s.cfg.AutoRecapTestChatID, messageText)
	msg.ParseMode = tgbotapi.ModeHTML
	msg.DisableWebPagePreview = false

	resp, err := s.bot.Send(msg)
	if err != nil {
		s.logger.Error("paging test: failed to send test message",
			zap.Error(err),
			zap.Int64("chat_id", s.cfg.AutoRecapTestChatID))
		return
	}

	s.logger.Info("paging test: successfully sent test message to chat",
		zap.Int64("chat_id", s.cfg.AutoRecapTestChatID),
		zap.Int("message_id", resp.MessageID),
		zap.Strings("urls", urls))
}

// CreatePage creates a new Telegraph page with the given title and HTML content.
// It returns the URL of the created page.
func (s *Service) CreatePage(ctx context.Context, title, html string) (string, error) {
	if s.cfg.Telegraph.AccessToken == "" {
		return "", fmt.Errorf("telegraph access token is not configured")
	}

	var page *telegraph.Page
	var lastErr error

	// ä½¿ç”¨ conc.WaitGroup ä¾†è™•ç†é‡è©¦é‚è¼¯
	wg := conc.NewWaitGroup()
	for i := 0; i < maxRetries; i++ {
		if i > 0 {
			time.Sleep(retryDelay)
		}

		wg.Go(func() {
			// ä½¿ç”¨ PageOpts è¨­ç½®ä½œè€…åç¨±
			opts := &telegraph.PageOpts{
				AuthorName:    "ZETA çš„ç¸½çµ AI",
				ReturnContent: false,
			}

			p, err := s.client.CreatePage(
				s.cfg.Telegraph.AccessToken,
				title,
				html,
				opts,
			)

			if err == nil {
				page = p
				return
			}

			lastErr = err
			s.logger.Warn("failed to create Telegraph page, retrying...",
				zap.Error(err),
				zap.String("title", title),
				zap.Int("attempt", i+1),
			)
		})
	}
	wg.Wait()

	if page == nil {
		s.logger.Error("all attempts to create Telegraph page failed",
			zap.Error(lastErr),
			zap.String("title", title),
		)
		return "", fmt.Errorf("failed to create Telegraph page after %d attempts: %w", maxRetries, lastErr)
	}

	// æå–è·¯å¾‘ï¼Œæ–¹ä¾¿æ—¥èªŒè¨˜éŒ„å’Œå¾ŒçºŒç·¨è¼¯
	path := strings.TrimPrefix(page.Url, "https://telegra.ph/")
	s.logger.Info("successfully created Telegraph page",
		zap.String("url", page.Url),
		zap.String("path", path),
		zap.String("title", title),
		zap.String("edit_url", fmt.Sprintf("https://edit.telegra.ph/%s", path)),
	)
	return page.Url, nil
}

// EditPage edits an existing Telegraph page with the given path, title and HTML content.
// It returns the URL of the edited page.
func (s *Service) EditPage(ctx context.Context, path, title, html string) (string, error) {
	if s.cfg.Telegraph.AccessToken == "" {
		return "", fmt.Errorf("telegraph access token is not configured")
	}

	var page *telegraph.Page
	var lastErr error

	// å¾è·¯å¾‘ä¸­ç§»é™¤ç¶²ç«™å‰ç¶´ï¼ˆå¦‚æœæœ‰ï¼‰
	path = strings.TrimPrefix(path, "https://telegra.ph/")

	// ä½¿ç”¨ conc.WaitGroup ä¾†è™•ç†é‡è©¦é‚è¼¯
	wg := conc.NewWaitGroup()
	for i := 0; i < maxRetries; i++ {
		if i > 0 {
			time.Sleep(retryDelay)
		}

		wg.Go(func() {
			// ä½¿ç”¨ PageOpts è¨­ç½®ä½œè€…åç¨±
			opts := &telegraph.PageOpts{
				AuthorName:    "ZETA çš„ç¸½çµ AI",
				ReturnContent: false,
			}

			p, err := s.client.EditPage(
				s.cfg.Telegraph.AccessToken,
				path,
				title,
				html,
				opts,
			)

			if err == nil {
				page = p
				return
			}

			lastErr = err
			s.logger.Warn("failed to edit Telegraph page, retrying...",
				zap.Error(err),
				zap.String("path", path),
				zap.String("title", title),
				zap.Int("attempt", i+1),
			)
		})
	}
	wg.Wait()

	if page == nil {
		s.logger.Error("all attempts to edit Telegraph page failed",
			zap.Error(lastErr),
			zap.String("path", path),
			zap.String("title", title),
		)
		return "", fmt.Errorf("failed to edit Telegraph page after %d attempts: %w", maxRetries, lastErr)
	}

	s.logger.Info("successfully edited Telegraph page",
		zap.String("url", page.Url),
		zap.String("path", path),
		zap.String("title", title),
	)
	return page.Url, nil
}

// DeletePage "deletes" a Telegraph page by setting its content to empty.
// Telegraph doesn't have a proper delete API, but we can effectively remove content.
// It returns true if the operation was successful.
func (s *Service) DeletePage(ctx context.Context, path string) (bool, error) {
	if s.cfg.Telegraph.AccessToken == "" {
		return false, fmt.Errorf("telegraph access token is not configured")
	}

	// å¾è·¯å¾‘ä¸­ç§»é™¤ç¶²ç«™å‰ç¶´ï¼ˆå¦‚æœæœ‰ï¼‰
	path = strings.TrimPrefix(path, "https://telegra.ph/")

	// å°‡é é¢å…§å®¹è¨­ç‚ºç©ºï¼Œå¯¦éš›ä¸Šå°±æ˜¯"åˆªé™¤"é é¢å…§å®¹
	emptyHTML := "<p>This page has been deleted</p>"

	var success bool
	var lastErr error

	// ä½¿ç”¨ conc.WaitGroup ä¾†è™•ç†é‡è©¦é‚è¼¯
	wg := conc.NewWaitGroup()
	for i := 0; i < maxRetries; i++ {
		if i > 0 {
			time.Sleep(retryDelay)
		}

		wg.Go(func() {
			// ä¿ç•™åŸæ¨™é¡Œï¼Œä½†æ¸…ç©ºå…§å®¹
			opts := &telegraph.PageOpts{
				AuthorName:    "ZETA çš„ç¸½çµ AI",
				ReturnContent: false,
			}

			_, err := s.client.EditPage(
				s.cfg.Telegraph.AccessToken,
				path,
				"Deleted Page", // å¯ä»¥æ›´æ›ç‚ºå…¶ä»–æ¨™é¡Œ
				emptyHTML,
				opts,
			)

			if err == nil {
				success = true
				return
			}

			lastErr = err
			s.logger.Warn("failed to delete Telegraph page, retrying...",
				zap.Error(err),
				zap.String("path", path),
				zap.Int("attempt", i+1),
			)
		})
	}
	wg.Wait()

	if !success {
		s.logger.Error("all attempts to delete Telegraph page failed",
			zap.Error(lastErr),
			zap.String("path", path),
		)
		return false, fmt.Errorf("failed to delete Telegraph page after %d attempts: %w", maxRetries, lastErr)
	}

	s.logger.Info("successfully deleted Telegraph page content",
		zap.String("path", path),
	)
	return true, nil
}

// FormatContent formats HTML content for Telegraph
func (s *Service) FormatContent(html string) (string, error) {
	nodes, err := telegraph.ContentFormat(html)
	if err != nil {
		return "", fmt.Errorf("failed to format content for Telegraph: %w", err)
	}

	contentBytes, err := json.Marshal(nodes)
	if err != nil {
		return "", fmt.Errorf("failed to marshal Telegraph nodes: %w", err)
	}

	return string(contentBytes), nil
}

// CheckContentLength checks if the HTML content length is too large for Telegraph API
func (s *Service) CheckContentLength(html string) bool {
	return len(html) < 64*1024 // Telegraph API limit is 64KB
}

// SplitContentIntoParts splits the HTML content into multiple parts if it's too large
// and returns a slice of HTML parts
func (s *Service) SplitContentIntoParts(html string, title string) []string {
	// å…ˆæª¢æŸ¥å…§å®¹è½‰æ›ç‚º JSON å¾Œçš„å¤§å°
	nodes, err := telegraph.ContentFormat(html)
	if err != nil {
		s.logger.Warn("failed to format content for Telegraph", zap.Error(err))
		// å¦‚æœæ ¼å¼åŒ–å¤±æ•—ï¼Œé€€å›åˆ°ä¾æ“šå­—ç¬¦è¨ˆç®—
		if len(html) < pageSizeLimit-safetyBuffer {
			return []string{html}
		}
	} else {
		jsonBytes, err := json.Marshal(nodes)
		if err != nil {
			s.logger.Warn("failed to marshal nodes for size check", zap.Error(err))
		} else if len(jsonBytes)+safetyBuffer < pageSizeLimit {
			// å¦‚æœæ•´å€‹å…§å®¹åœ¨å¤§å°é™åˆ¶å…§ï¼Œç›´æ¥è¿”å›
			s.logger.Info("content size check passed, no need for splitting",
				zap.Int("json_size", len(jsonBytes)),
				zap.Int("limit", pageSizeLimit))
			return []string{html}
		}
	}

	// å°‹æ‰¾é©åˆçš„åˆ†å‰²é»ï¼šä¿æŒHTMLçµæ§‹å®Œæ•´æ€§
	parts := []string{}
	currentPart := ""
	paragraphs := strings.Split(html, "</p>")

	// æ·»åŠ æ¨™é¡Œå’Œèªªæ˜
	headerHTML := "<p><strong>æ³¨æ„ï¼š</strong>ç”±æ–¼å…§å®¹è¼ƒé•·ï¼Œå·²è‡ªå‹•åˆ†å‰²ç‚ºå¤šå€‹é é¢</p><hr>"
	currentPart = headerHTML

	for i, p := range paragraphs {
		// æ·»åŠ é–‰åˆæ¨™ç±¤
		if i < len(paragraphs)-1 || strings.TrimSpace(p) != "" {
			p = p + "</p>"
		}

		// æª¢æŸ¥æ·»åŠ æ­¤æ®µå¾Œæ˜¯å¦æœƒè¶…å‡ºé™åˆ¶
		testHTML := currentPart + p
		nodes, err := telegraph.ContentFormat(testHTML)
		if err != nil {
			s.logger.Warn("failed to format content for size check",
				zap.Error(err),
				zap.Int("current_part_length", len(currentPart)),
				zap.Int("paragraph_length", len(p)))

			// å¦‚æœæ ¼å¼åŒ–å¤±æ•—ï¼Œé€€å›åˆ°ä¾æ“šå­—ç¬¦è¨ˆç®—
			if len(testHTML) >= pageSizeLimit-safetyBuffer {
				// ç•¶å‰éƒ¨åˆ†å·²æ»¿ï¼Œæ·»åŠ é è…³ä¸¦ä¿å­˜
				footerHTML := "<hr><p><em>ï¼ˆæœ¬é é¢ç‚ºåˆ†å‰²å…§å®¹ï¼Œè«‹æŸ¥çœ‹ç³»åˆ—é é¢ç²å–å®Œæ•´ç¸½çµï¼‰</em></p>"
				currentPart += footerHTML
				parts = append(parts, currentPart)

				// é–‹å§‹æ–°çš„éƒ¨åˆ†ï¼Œæ·»åŠ é é¢æ¨™é¡Œå’Œæç¤º
				currentPart = fmt.Sprintf("<p><strong>%sï¼ˆçºŒ %dï¼‰</strong></p>", title, len(parts)+1)
				currentPart += "<p><strong>æ³¨æ„ï¼š</strong>é€™æ˜¯åˆ†å‰²å…§å®¹çš„çºŒé </p><hr>"
				currentPart += p // æ·»åŠ ç•¶å‰æ®µè½åˆ°æ–°é é¢
				continue
			}
		} else {
			jsonBytes, err := json.Marshal(nodes)
			if err != nil {
				s.logger.Warn("failed to marshal nodes for size check", zap.Error(err))
			} else if len(jsonBytes)+safetyBuffer >= pageSizeLimit {
				s.logger.Info("splitting content at paragraph",
					zap.Int("part_index", len(parts)+1),
					zap.Int("json_size", len(jsonBytes)),
					zap.Int("limit", pageSizeLimit))

				// ç•¶å‰éƒ¨åˆ†å·²æ»¿ï¼Œæ·»åŠ é è…³ä¸¦ä¿å­˜
				footerHTML := "<hr><p><em>ï¼ˆæœ¬é é¢ç‚ºåˆ†å‰²å…§å®¹ï¼Œè«‹æŸ¥çœ‹ç³»åˆ—é é¢ç²å–å®Œæ•´ç¸½çµï¼‰</em></p>"
				currentPart += footerHTML
				parts = append(parts, currentPart)

				// é–‹å§‹æ–°çš„éƒ¨åˆ†ï¼Œæ·»åŠ é é¢æ¨™é¡Œå’Œæç¤º
				currentPart = fmt.Sprintf("<p><strong>%sï¼ˆçºŒ %dï¼‰</strong></p>", title, len(parts)+1)
				currentPart += "<p><strong>æ³¨æ„ï¼š</strong>é€™æ˜¯åˆ†å‰²å…§å®¹çš„çºŒé </p><hr>"
				currentPart += p // æ·»åŠ ç•¶å‰æ®µè½åˆ°æ–°é é¢
				continue
			}
		}

		// å¦‚æœæ²’æœ‰è¶…éå¤§å°é™åˆ¶ï¼Œæ·»åŠ æ®µè½åˆ°ç•¶å‰éƒ¨åˆ†
		currentPart += p
	}

	// æ·»åŠ æœ€å¾Œä¸€éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰å…§å®¹çš„è©±ï¼‰
	if len(currentPart) > 0 && currentPart != headerHTML {
		footerHTML := "<hr><p><em>ï¼ˆç³»åˆ—é é¢çµæŸï¼‰</em></p>"
		currentPart += footerHTML
		parts = append(parts, currentPart)
	}

	s.logger.Info("content successfully split into parts",
		zap.Int("total_parts", len(parts)))

	return parts
}

// CreatePageSeries creates a series of Telegraph pages if content is too large
// It returns a slice of URLs for all created pages
func (s *Service) CreatePageSeries(ctx context.Context, title string, html string) ([]string, error) {
	if s.cfg.Telegraph.AccessToken == "" {
		return nil, fmt.Errorf("telegraph access token is not configured")
	}

	// åˆ†å‰²å…§å®¹
	parts := s.SplitContentIntoParts(html, title)
	urls := make([]string, 0, len(parts))
	pageTitles := make([]string, 0, len(parts))
	var createErrors []error

	// å…ˆå‰µå»ºæ‰€æœ‰é é¢
	for i, part := range parts {
		pageTitle := title
		if i > 0 {
			// ç‚ºå¤šé æ·»åŠ æ›´æœ‰æ„ç¾©çš„æ¨™é¡Œå¾Œç¶´
			pageTitle = fmt.Sprintf("%sï¼ˆç¬¬ %d éƒ¨åˆ†ï¼‰", title, i+1)
		}

		url, err := s.CreatePage(ctx, pageTitle, part)
		if err != nil {
			s.logger.Error("failed to create part of the Telegraph page series",
				zap.Error(err),
				zap.String("title", pageTitle),
				zap.Int("part", i+1),
				zap.Int("total_parts", len(parts)),
			)
			createErrors = append(createErrors, err)
			continue
		}

		urls = append(urls, url)
		pageTitles = append(pageTitles, pageTitle)

		// throttle to avoid ACCESS_TOKEN_INVALID
		time.Sleep(pageCreateInterval)
	}

	// æª¢æŸ¥æ˜¯å¦æ‰€æœ‰é é¢éƒ½å‰µå»ºæˆåŠŸ
	if len(createErrors) > 0 {
		return urls, fmt.Errorf("failed to create some pages in series: %v", createErrors)
	}

	if len(urls) == 0 {
		return nil, fmt.Errorf("failed to create any Telegraph pages for the series")
	}

	// ç”Ÿæˆç³»åˆ—éˆæ¥ HTML
	seriesHeader := "<p><strong>ç³»åˆ—é é¢ï¼š</strong></p><ul>"
	for i, u := range urls {
		seriesHeader += fmt.Sprintf("<li><a href=\"%s\">ç¬¬ %d éƒ¨åˆ†</a></li>", u, i+1)
	}
	seriesHeader += "</ul><hr>"

	// ç­‰å¾…ä¸€æ®µæ™‚é–“å†é€²è¡Œç·¨è¼¯ï¼Œé¿å… token å¤±æ•ˆ
	time.Sleep(pageCreateInterval * 2)

	// é€é ç·¨è¼¯ï¼Œæ’å…¥éˆæ¥
	var editErrors []error
	for i, u := range urls {
		path := strings.TrimPrefix(u, "https://telegra.ph/")
		newHTML := seriesHeader + parts[i]
		_, err := s.EditPage(ctx, path, pageTitles[i], newHTML)
		if err != nil {
			s.logger.Warn("failed to edit page to add series links",
				zap.Error(err),
				zap.String("url", u),
				zap.Int("page", i+1),
			)
			editErrors = append(editErrors, err)
		}

		time.Sleep(pageCreateInterval)
	}

	// è¨˜éŒ„ç·¨è¼¯éŒ¯èª¤ä½†ä¸ä¸­æ–·æµç¨‹
	if len(editErrors) > 0 {
		s.logger.Error("some pages failed to be edited with series links",
			zap.Errors("errors", editErrors))
	}

	s.logger.Info("successfully created Telegraph page series",
		zap.Int("total_pages", len(urls)),
		zap.String("title", title),
		zap.Strings("urls", urls),
	)

	return urls, nil
}
